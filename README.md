# mindgain

### Inspiration
I often experience subtle cognitive symptoms like forgetfulness, zoning out, or emotional fatigue without immediately recognizing that it is my mind signaling burnout. According to a 2023 survey by the American College Health Association, over 78% of students reported feeling overwhelmed in the past year, and more than 60% experienced frequent mental exhaustion. Despite those numbers, many people like me do not seek help, whether because of stigma or simply a lack of awareness about what is happening. This inspires me to create a companion that does not just ask how you are feeling, but quietly listens to the signals we often miss in our everyday, subconscious experience.

### What it does
mindgain is an AI-powered cognitive wellness companion that uses voice analysis to recognize subtle signs of mental strain. Instead of focusing on words alone, it listens for patterns in tone, rhythm, and pacing to detect indicators of fatigue, memory stress, or emotional imbalance. Through a short 15-second voice journal, users receive gentle insights into their mental state, along with thoughtful prompts that encourage self-awareness and emotional care. The experience is meant to feel like speaking into a mirror that quietly reflects how your mind is doing, offering clarity without judgment.

### How we built it
I built mindgain using a convolutional neural network trained on mel-spectrograms, leveraging pseudo-labeling techniques inspired by my Alzheimer's detection research. The model was developed in PyTorch and fine-tuned to detect subtle paralinguistic cues in short audio clips. For preprocessing, I used Librosa to extract acoustic features such as jitter, pause length, and tone modulation. The UI was prototyped using Gradio to support real-time voice input, playback, and feedback, while Matplotlib helped visualize emotional trends across sessions. Each voice entry is analyzed locally to preserve user privacy while still offering meaningful, personalized feedback.

### Challenges we ran into
One of the biggest challenges I faced was the absence of a standardized dataset specifically for identifying student burnout or cognitive fatigue. To address this, I adapted dementia-related datasets like the DementiaBank Pitt Corpus and focused on acoustic features that generalize across age groups. Rather than relying solely on clinical speech markers, I emphasized what I call the invisible inheritance of mental strain. Another major challenge was maintaining user privacy while ensuring the system remained emotionally supportive. Instead of storing raw voice recordings, I extracted only anonymized acoustic features to deliver meaningful insights without compromising personal data.

### Accomplishments that we're proud of
I am proud to have adapted a research-level model into a wellness-focused companion designed for students. Using semi-supervised learning on unlabeled audio samples, I achieved approximately 88% pseudo-accuracy, one of the highest reported for speech-only Alzheimer's detection models based on spectrograms. The model is lightweight, privacy-conscious, and ready for real-world use. Perhaps even more importantly, the app’s interface feels calming and reflective, more like a personal check-in space than a clinical diagnosis tool.

### What we learned
Throughout building mindgain, I discovered that voice carries much more than spoken content. It holds emotional and cognitive signals that often go unnoticed. Research in psychology supports this, showing that paralinguistic features such as tone, pitch, and rhythm can reflect a person’s mental and emotional state even when their words do not. I also learned that in wellness tools, empathy and trust are just as important as technical accuracy. The subtle design choices such as calming color palettes and fluid waveform animations can significantly shape how users feel, fostering a sense of comfort, emotional safety, and engagement.

### What's next for mindgain
In the future, I plan to expand the dataset by inviting students to contribute anonymous voice journals. This will help fine-tune the model using more diverse and relevant audio samples, while enabling features like multi-day tracking to help users better understand their cognitive and emotional patterns. I also aim to integrate mindgain with wearable devices and wellness apps to offer smarter, context-aware feedback. Ultimately, I hope to publish my research and open-source key components to promote ethical, transparent, and accessible AI for everyone.
